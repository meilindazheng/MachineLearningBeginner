{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fd76a03",
   "metadata": {},
   "source": [
    "# Mengenal Text Processing : Bags of Words & Stop Word Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2b64c6",
   "metadata": {},
   "source": [
    "## Bag of Words model sebagai representasi text\n",
    "Bag of Words menyederhanakan representasi text sebagai sekumpulan kata serta mengabaikan grammar dan posisi tiap kata pada kalimat. Text akan dikonversi menjadi lowercase dan tanda baca akan diabaikan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fff5a14",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e120c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linux has been around since mid 1990-s',\n",
       " 'Linux distributions include the Linux-kernel',\n",
       " 'Linux is one of the most prominent open-source software']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    'linux has been around since mid 1990-s',\n",
    "    'Linux distributions include the Linux-kernel',\n",
    "    'Linux is one of the most prominent open-source software'\n",
    "]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01dcaa8",
   "metadata": {},
   "source": [
    "## Bag of Words model dengan CountVectorizer\n",
    "- method todense() digunakan untuk mentransformasikan sebuah objek menjadi array\n",
    "- Nilai pada array yang berkorelasi dengan feature_names merepresentasikan jumlah kemunculan token dalam kalimat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93fe1438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1]],\n",
       "       dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "vectorized_X = vectorizer.fit_transform(corpus).todense()\n",
    "vectorized_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16cd7731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1990',\n",
       " 'around',\n",
       " 'been',\n",
       " 'distributions',\n",
       " 'has',\n",
       " 'include',\n",
       " 'is',\n",
       " 'kernel',\n",
       " 'linux',\n",
       " 'mid',\n",
       " 'most',\n",
       " 'of',\n",
       " 'one',\n",
       " 'open',\n",
       " 'prominent',\n",
       " 'since',\n",
       " 'software',\n",
       " 'source',\n",
       " 'the']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87629dce",
   "metadata": {},
   "source": [
    "## Euclidean Distance untuk mengukur kedekatan / jarak antar dokumen (vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "980703c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jarak dokumen 1 dan 2 adalah [[3.31662479]]\n",
      "Jarak dokumen 1 dan 3 adalah [[3.87298335]]\n",
      "Jarak dokumen 2 dan 3 adalah [[3.46410162]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "for i in range (len(vectorized_X)):\n",
    "    for j in range (i,len(vectorized_X)):\n",
    "        if i == j :\n",
    "            continue\n",
    "        jarak = euclidean_distances(vectorized_X[i],vectorized_X[j])\n",
    "        print(f'Jarak dokumen {i+1} dan {j+1} adalah {jarak}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855a5620",
   "metadata": {},
   "source": [
    "## Stop Word pada Filtering Text\n",
    "Stop Word menyerdehanakan representasi text dengan mengabaikan beberapa kata seperti determiners (the,a,an), auxiliary verbs (do,be,will) dan prepositions (on,in,at)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c28958",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7adafceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linux has been around since mid 1990-s',\n",
       " 'Linux distributions include the Linux-kernel',\n",
       " 'Linux is one of the most prominent open-source software']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ae5b0e",
   "metadata": {},
   "source": [
    "### Stop Word Filtering dengan countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8147f29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 1, 1, 2, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vectorized_X = vectorizer.fit_transform(corpus).todense()\n",
    "vectorized_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a719a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1990',\n",
       " 'distributions',\n",
       " 'include',\n",
       " 'kernel',\n",
       " 'linux',\n",
       " 'mid',\n",
       " 'open',\n",
       " 'prominent',\n",
       " 'software',\n",
       " 'source']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e990a4",
   "metadata": {},
   "source": [
    "# Mengenal TF-IDF (Terms Frequency - Inverse Document Frequency)\n",
    "- TF-IDF digunakan untuk mengukur seberapa penting sebuah kata terhadap dokumen dari sekumpulan dokumen atau corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b89429",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d8f701d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the house had a tiny little mouse',\n",
       " 'the cat saw the mouse',\n",
       " 'the mouse ran away from the house',\n",
       " 'the cat finally ate the  mouse',\n",
       " 'the end of the mouse story']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    'the house had a tiny little mouse',\n",
    "    'the cat saw the mouse',\n",
    "    'the mouse ran away from the house',\n",
    "    'the cat finally ate the  mouse',\n",
    "    'the end of the mouse story'\n",
    "]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644d4b79",
   "metadata": {},
   "source": [
    "## TF-IDF Weights dengan TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1396d21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7)\t0.2808823162882302\n",
      "  (0, 6)\t0.5894630806320427\n",
      "  (0, 11)\t0.5894630806320427\n",
      "  (0, 5)\t0.47557510189256375\n",
      "  (1, 9)\t0.7297183669435993\n",
      "  (1, 2)\t0.5887321837696324\n",
      "  (1, 7)\t0.3477147117091919\n",
      "  (2, 1)\t0.5894630806320427\n",
      "  (2, 8)\t0.5894630806320427\n",
      "  (2, 7)\t0.2808823162882302\n",
      "  (2, 5)\t0.47557510189256375\n",
      "  (3, 0)\t0.5894630806320427\n",
      "  (3, 4)\t0.5894630806320427\n",
      "  (3, 2)\t0.47557510189256375\n",
      "  (3, 7)\t0.2808823162882302\n",
      "  (4, 10)\t0.6700917930430479\n",
      "  (4, 3)\t0.6700917930430479\n",
      "  (4, 7)\t0.3193023297639811\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "response = vectorizer.fit_transform(corpus)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efc20057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ate',\n",
       " 'away',\n",
       " 'cat',\n",
       " 'end',\n",
       " 'finally',\n",
       " 'house',\n",
       " 'little',\n",
       " 'mouse',\n",
       " 'ran',\n",
       " 'saw',\n",
       " 'story',\n",
       " 'tiny']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82190707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4755751 , 0.58946308, 0.28088232, 0.        , 0.        ,\n",
       "         0.        , 0.58946308],\n",
       "        [0.        , 0.        , 0.58873218, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.34771471, 0.        , 0.72971837,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.58946308, 0.        , 0.        , 0.        ,\n",
       "         0.4755751 , 0.        , 0.28088232, 0.58946308, 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.58946308, 0.        , 0.4755751 , 0.        , 0.58946308,\n",
       "         0.        , 0.        , 0.28088232, 0.        , 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.67009179, 0.        ,\n",
       "         0.        , 0.        , 0.31930233, 0.        , 0.        ,\n",
       "         0.67009179, 0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06bf3a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ate</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.589463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>away</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.589463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.588732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475575</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.670092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finally</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.589463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <td>0.475575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>0.589463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mouse</th>\n",
       "      <td>0.280882</td>\n",
       "      <td>0.347715</td>\n",
       "      <td>0.280882</td>\n",
       "      <td>0.280882</td>\n",
       "      <td>0.319302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ran</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.589463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saw</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.729718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.670092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiny</th>\n",
       "      <td>0.589463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               D1        D2        D3        D4        D5\n",
       "ate      0.000000  0.000000  0.000000  0.589463  0.000000\n",
       "away     0.000000  0.000000  0.589463  0.000000  0.000000\n",
       "cat      0.000000  0.588732  0.000000  0.475575  0.000000\n",
       "end      0.000000  0.000000  0.000000  0.000000  0.670092\n",
       "finally  0.000000  0.000000  0.000000  0.589463  0.000000\n",
       "house    0.475575  0.000000  0.475575  0.000000  0.000000\n",
       "little   0.589463  0.000000  0.000000  0.000000  0.000000\n",
       "mouse    0.280882  0.347715  0.280882  0.280882  0.319302\n",
       "ran      0.000000  0.000000  0.589463  0.000000  0.000000\n",
       "saw      0.000000  0.729718  0.000000  0.000000  0.000000\n",
       "story    0.000000  0.000000  0.000000  0.000000  0.670092\n",
       "tiny     0.589463  0.000000  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame(response.todense().T,\n",
    "                 index = vectorizer.get_feature_names(),\n",
    "                 columns=[f'D{i+1}' for i in range(len(corpus))])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc58f68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
